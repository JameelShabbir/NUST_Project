{"cells":[{"cell_type":"markdown","metadata":{"id":"FStp_vbUkRz5"},"source":["\n","\n","\n","# Transfer Learning\n","In this notebook, we will perform transfer learning to train CIFAR-10 dataset on ResNet50 model available in Keras.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qpiJj8ym0v0-"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:04:46.451429Z","iopub.status.busy":"2023-07-21T11:04:46.45022Z","iopub.status.idle":"2023-07-21T11:05:05.442804Z","shell.execute_reply":"2023-07-21T11:05:05.441717Z","shell.execute_reply.started":"2023-07-21T11:04:46.451382Z"},"id":"AoilhmYe1b5t","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mImage\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mImageFont\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mImageDraw\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresnet50\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet50\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import os, re, time, json\n","import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from matplotlib import pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","print(\"Tensorflow version \" + tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"HuG_q_1jkaZ6"},"source":["## Parameters"]},{"cell_type":"markdown","metadata":{"id":"v4ocPhg6J_xw"},"source":["- Define the batch size\n","- Define the class (category) names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:05.445416Z","iopub.status.busy":"2023-07-21T11:05:05.444833Z","iopub.status.idle":"2023-07-21T11:05:05.455417Z","shell.execute_reply":"2023-07-21T11:05:05.453353Z","shell.execute_reply.started":"2023-07-21T11:05:05.445387Z"},"id":"cCpkS9C_H7Tl","trusted":true},"outputs":[],"source":["BATCH_SIZE = 32 \n","label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"]},{"cell_type":"markdown","metadata":{"id":"O-o96NnyJ_xx"},"source":["Define some functions that will help us to create some visualizations. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:05.461925Z","iopub.status.busy":"2023-07-21T11:05:05.460909Z","iopub.status.idle":"2023-07-21T11:05:05.489875Z","shell.execute_reply":"2023-07-21T11:05:05.48855Z","shell.execute_reply.started":"2023-07-21T11:05:05.461856Z"},"id":"CfFqJxrzoj5Q","trusted":true},"outputs":[],"source":["\n","\n","# utility to display training and validation curves\n","def plot_metrics(metric_name, title, ylim=5):\n","  plt.title(title)\n","  plt.ylim(0,ylim)\n","  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n","  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"]},{"cell_type":"markdown","metadata":{"id":"wPq4Sw5akosT"},"source":["## Loading and Preprocessing Data\n","[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset has 32 x 32 RGB images belonging to 10 classes. We will load the dataset from Keras."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:05.495351Z","iopub.status.busy":"2023-07-21T11:05:05.494347Z","iopub.status.idle":"2023-07-21T11:05:10.70877Z","shell.execute_reply":"2023-07-21T11:05:10.707725Z","shell.execute_reply.started":"2023-07-21T11:05:05.495312Z"},"id":"E103YDdQ8NNq","trusted":true},"outputs":[],"source":["(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()"]},{"cell_type":"markdown","metadata":{"id":"prd944ThNavt"},"source":["### Visualize Train Dataset\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:10.71125Z","iopub.status.busy":"2023-07-21T11:05:10.710594Z","iopub.status.idle":"2023-07-21T11:05:11.589469Z","shell.execute_reply":"2023-07-21T11:05:11.588446Z","shell.execute_reply.started":"2023-07-21T11:05:10.711212Z"},"id":"UiokWTuKo88c","trusted":true},"outputs":[],"source":["# Create a subplot\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","      # Display the image\n","      ax = plt.subplot(3, 3, i + 1)\n","      plt.imshow(training_images[i], cmap='gray')\n","      # Print the label\n","      plt.title(\"Label=\"+label_names[ training_labels[i][0]])\n","      plt.axis('off')\n","\n","# Show the subplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:11.591879Z","iopub.status.busy":"2023-07-21T11:05:11.590645Z","iopub.status.idle":"2023-07-21T11:05:12.402285Z","shell.execute_reply":"2023-07-21T11:05:12.401342Z","shell.execute_reply.started":"2023-07-21T11:05:11.591838Z"},"id":"-q35q41KNfxH","trusted":true},"outputs":[],"source":["# Create a subplot\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","      # Display the image\n","      ax = plt.subplot(3, 3, i + 1)\n","      plt.imshow(validation_images[i], cmap='gray')\n","      # Print the label\n","      plt.title(\"Label=\"+label_names[ validation_labels[i][0]])\n","      plt.axis('off')\n","\n","# Show the subplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ltKfwrCVNuIu"},"source":["### Preprocess Dataset\n","Here, we'll perform normalization on images in training and validation set. \n","- We'll use the function [preprocess_input](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py) from the ResNet50 model in Keras."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:12.404562Z","iopub.status.busy":"2023-07-21T11:05:12.403853Z","iopub.status.idle":"2023-07-21T11:05:12.409469Z","shell.execute_reply":"2023-07-21T11:05:12.408249Z","shell.execute_reply.started":"2023-07-21T11:05:12.404501Z"},"trusted":true},"outputs":[],"source":["#trfd=tf.keras.applications.resnet50.preprocess_input(training_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:12.411761Z","iopub.status.busy":"2023-07-21T11:05:12.411105Z","iopub.status.idle":"2023-07-21T11:05:12.423609Z","shell.execute_reply":"2023-07-21T11:05:12.422586Z","shell.execute_reply.started":"2023-07-21T11:05:12.411725Z"},"trusted":true},"outputs":[],"source":["#trfd.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:12.425748Z","iopub.status.busy":"2023-07-21T11:05:12.425286Z","iopub.status.idle":"2023-07-21T11:05:12.43372Z","shell.execute_reply":"2023-07-21T11:05:12.432811Z","shell.execute_reply.started":"2023-07-21T11:05:12.425702Z"},"id":"JIxdiJVKArC6","trusted":true},"outputs":[],"source":["def preprocess_image_input(input_images):\n","  input_images = input_images.astype('float32')\n","  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n","  return output_ims\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:12.438603Z","iopub.status.busy":"2023-07-21T11:05:12.438328Z","iopub.status.idle":"2023-07-21T11:05:12.827776Z","shell.execute_reply":"2023-07-21T11:05:12.826729Z","shell.execute_reply.started":"2023-07-21T11:05:12.438578Z"},"id":"QOqjKzgAEU-Z","trusted":true},"outputs":[],"source":["train_X = preprocess_image_input(training_images)\n","valid_X = preprocess_image_input(validation_images)"]},{"cell_type":"markdown","metadata":{"id":"2fooPL9Gkuox"},"source":["## Define the Network\n","We will be performing transfer learning on **ResNet50** available in Keras.\n","- We'll load pre-trained **imagenet weights** to the model.\n","- We'll choose to retain all layers of **ResNet50** along with the final classification layers."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:12.829704Z","iopub.status.busy":"2023-07-21T11:05:12.829212Z","iopub.status.idle":"2023-07-21T11:05:22.810816Z","shell.execute_reply":"2023-07-21T11:05:22.809754Z","shell.execute_reply.started":"2023-07-21T11:05:12.829645Z"},"id":"56y8UNFQIVwj","trusted":true},"outputs":[],"source":["'''\n","Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n","Input size is 224 x 224.\n","'''\n","def feature_extractor(inputs):\n","\n","  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n","                                               include_top=False,\n","                                               weights='imagenet')(inputs)\n","  return feature_extractor\n","\n","\n","'''\n","Defines final dense layers and subsequent softmax layer for classification.\n","'''\n","def classifier(inputs):\n","    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n","    x = tf.keras.layers.Flatten()(x)\n","    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n","    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n","    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n","    return x\n","\n","'''\n","Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\n","Connect the feature extraction and \"classifier\" layers to build the model.\n","'''\n","def final_model(inputs):\n","\n","    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n","\n","    resnet_feature_extractor = feature_extractor(resize)\n","    classification_output = classifier(resnet_feature_extractor)\n","\n","    return classification_output\n","\n","'''\n","Define the model and compile it. \n","Use Stochastic Gradient Descent as the optimizer.\n","Use Sparse Categorical CrossEntropy as the loss function.\n","'''\n","def define_compile_model():\n","  inputs = tf.keras.layers.Input(shape=(32,32,3))\n","  \n","  classification_output = final_model(inputs) \n","  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n"," \n","  model.compile(optimizer='SGD', \n","                loss='sparse_categorical_crossentropy',\n","                metrics = ['accuracy'])\n","  \n","  return model\n","\n","\n","model = define_compile_model()\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"CuhDh8ao8VyB"},"source":["## Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-21T11:05:22.813133Z","iopub.status.busy":"2023-07-21T11:05:22.812259Z","iopub.status.idle":"2023-07-21T11:06:08.638829Z","shell.execute_reply":"2023-07-21T11:06:08.637178Z","shell.execute_reply.started":"2023-07-21T11:05:22.813089Z"},"id":"2K6RNDqtJ_xx","trusted":true},"outputs":[],"source":["EPOCHS = 3\n","history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=128)"]},{"cell_type":"markdown","metadata":{"id":"CYb5sAEmk4ut"},"source":["## Evaluate the Model\n","\n","Calculate the loss and accuracy metrics using the model's `.evaluate` function."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.640108Z","iopub.status.idle":"2023-07-21T11:06:08.641476Z","shell.execute_reply":"2023-07-21T11:06:08.641225Z","shell.execute_reply.started":"2023-07-21T11:06:08.641197Z"},"trusted":true},"outputs":[],"source":["loss, t_accuracy = model.evaluate(train_X, training_labels, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.643155Z","iopub.status.idle":"2023-07-21T11:06:08.643734Z","shell.execute_reply":"2023-07-21T11:06:08.643467Z","shell.execute_reply.started":"2023-07-21T11:06:08.64344Z"},"id":"io7Fuu-w3PZi","trusted":true},"outputs":[],"source":["\n","loss, v_accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.645649Z","iopub.status.idle":"2023-07-21T11:06:08.646171Z","shell.execute_reply":"2023-07-21T11:06:08.645936Z","shell.execute_reply.started":"2023-07-21T11:06:08.645912Z"},"trusted":true},"outputs":[],"source":["print(\"Train Acc:\",t_accuracy)\n","print(\"Test Acc:\",v_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.647994Z","iopub.status.idle":"2023-07-21T11:06:08.648519Z","shell.execute_reply":"2023-07-21T11:06:08.648277Z","shell.execute_reply.started":"2023-07-21T11:06:08.648252Z"},"id":"NIQAqkMV9adq","trusted":true},"outputs":[],"source":["# Predict the label for 9 images\n","test_images_9 = validation_images[:9]\n","test_labels_9 = validation_labels[:9]\n","# Create a subplot\n","fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n","\n","for i in range(9):\n","  test_images_9_1 = np.reshape(test_images_9[i], (1, 32, 32,3))\n","  prediction = model.predict(test_images_9_1)\n","  axes[i // 3, i % 3] = plt.subplot(3, 3, i + 1)\n","  axes[i // 3, i % 3].imshow(test_images_9[i])\n","  axes[i // 3, i % 3].set_title(f\"Predicted: {label_names[prediction.argmax()] }\")\n","  axes[i // 3, i % 3].set_ylabel(\"Label=\"+label_names[test_labels_9[i][0]])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Data Augmentation\n"]},{"cell_type":"markdown","metadata":{},"source":["![](http://)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.650433Z","iopub.status.idle":"2023-07-21T11:06:08.650959Z","shell.execute_reply":"2023-07-21T11:06:08.650724Z","shell.execute_reply.started":"2023-07-21T11:06:08.650699Z"},"trusted":true},"outputs":[],"source":["(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.654783Z","iopub.status.idle":"2023-07-21T11:06:08.655876Z","shell.execute_reply":"2023-07-21T11:06:08.655599Z","shell.execute_reply.started":"2023-07-21T11:06:08.655568Z"},"trusted":true},"outputs":[],"source":["#img = preprocess_image_input(validation_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.657679Z","iopub.status.idle":"2023-07-21T11:06:08.658227Z","shell.execute_reply":"2023-07-21T11:06:08.657978Z","shell.execute_reply.started":"2023-07-21T11:06:08.657953Z"},"trusted":true},"outputs":[],"source":["train_X = preprocess_image_input(training_images)\n","valid_X = preprocess_image_input(validation_images)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation using ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.660145Z","iopub.status.idle":"2023-07-21T11:06:08.660656Z","shell.execute_reply":"2023-07-21T11:06:08.660413Z","shell.execute_reply.started":"2023-07-21T11:06:08.66039Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# Create an instance of the ImageDataGenerator class.\n","datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n",")\n","\n","# Load the images.\n","train_X = datagen.flow(\n","    train_X,\n","    training_labels,\n","    batch_size=32,\n","    \n",")\n","\n","valid_X = datagen.flow(\n","    valid_X,\n","    validation_labels,\n","    batch_size=32,\n","    \n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.662581Z","iopub.status.idle":"2023-07-21T11:06:08.663157Z","shell.execute_reply":"2023-07-21T11:06:08.662874Z","shell.execute_reply.started":"2023-07-21T11:06:08.662849Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 3\n","history = model.fit(train_X, epochs=3, validation_data = (valid_X), batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-21T11:06:08.665077Z","iopub.status.idle":"2023-07-21T11:06:08.665652Z","shell.execute_reply":"2023-07-21T11:06:08.66541Z","shell.execute_reply.started":"2023-07-21T11:06:08.665385Z"},"trusted":true},"outputs":[],"source":["loss, t_accuracy = model.evaluate(train_X, training_labels, batch_size=64)\n","loss, v_accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)\n","print(\"Train Acc:\",t_accuracy)\n","print(\"Test Acc:\",v_accuracy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
